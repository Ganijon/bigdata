# Project: Distributed algorithms in Spark to Apache log Analysis

## Objective

In this project we will create algorithms in Scala to analyze Apache access logs.

## Implementation Plan

### Part 1. Set up a single node cluster and eclipse development environment to create and test programs.
    Install VMWare or VirtualBox hypervisor
    Install Cloudera Hadoop virtual machine
    
### Part 2. Find all IP addresses that accessed server more than 10 times.
    Create Scala code (.scala file) 
    Show input, output file

### Part 3. Calculate statistics based on the content size.
    Create Scala code (.scala file) 
    Show input, output file

### Part 4. Count Response Codes.
    Create Scala code (.scala file) 
    Show input, output file

### Part 5. Top 10 Endpoints
    Create Scala code (.scala file) 
    Show input, output file

### Resources:

    1. www.tutorialspoint.com//apache_spark/index.htm

    2. www.monitorware.com/en/logsamples/apache.php


### SPARK Project Binaries:

    /usr/bin/spark-shell

    /etc/spark/conf

### RDD Creation:

    To access HDFS files (hdfs:///user/cloudera/ ....) 

    To access Linux file (file:///home/...)
